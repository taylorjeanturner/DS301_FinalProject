---
title: "finalGroupProject - Kordell Schrock"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(leaps)
library(caret)
library(ISLR2)
library(glmnet)
library(boot)
library (plyr)
library(MASS)
library(class)
library(heplots)
library(ggplot2)
library(dplyr)
library(gridExtra)
library(ROCR)
library(data.table)
df = read.csv('./heart_2020_cleaned.csv')
df$HeartDisease <- ifelse(df$HeartDisease == 'Yes', 1, 0)
df$Smoking = factor(df$Smoking)
df$AlcoholDrinking = factor(df$AlcoholDrinking)
df$Stroke = factor(df$Stroke)
df$DiffWalking = factor(df$DiffWalking)
df$Sex = factor(df$Sex)
df$AgeCategory = factor(df$AgeCategory)
df$Race = factor(df$Race)
df$Diabetic = factor(df$Diabetic)
df$PhysicalActivity = factor(df$PhysicalActivity)
df$GenHealth = factor(df$GenHealth)
df$Asthma = factor(df$Asthma)
df$KidneyDisease = factor(df$KidneyDisease)
df$SkinCancer = factor(df$SkinCancer)
```
# Lasso Regression 1:
#### Use 10-fold CV to obtain the optimal λ. Present a plot of the cross-validation error as a function of λ. Report that value here

#### Prediction: Given other predictors like age, kidney disease, skin cancer, heart disease, etc, can we predict the BMI of a person?
##### here the model finds that HeartDisease is the best predictor in predicting BMI
```{r}
set.seed(1)
grid <- 10^seq(10,-2,length= 100)
train <- sample(1:nrow(df), nrow(df)/2) 
test <- (-train)
y = df$BMI
y.test <-  y[test]
               
x = model.matrix(BMI ~.,df)[,-1] 
y = df[,1] 

lassoo.train = glmnet(x[train,],y[train],alpha=1,lambda=grid)
cv.out <- cv.glmnet(x[train,], y[train], alpha=1)
plot(cv.out)
bestlambda = cv.out$lambda.min
bestlambda
log(bestlambda) #confirm min aligns with min on plot
lasso.pred = predict(lassoo.train,s=bestlambda,newx=x[test,])
mean((lasso.pred-y.test)^2)

final.lasso = glmnet(x,y,alpha=1,lambda=bestlambda)
coef(final.lasso)
lasso_coef2=cv.out$glmnet.fit$beta[, cv.out$glmnet.fit$lambda ==bestlambda]

```
# Lasso Regression 2:
#### Prediction: Given other predictors like age, kidney disease, skin cancer, heart disease, etc, can we predict the BMI of a person?REMOVING heart disease predictor
##### removed predictor HeartDisease, to find another model
```{r}
set.seed(1)
grid = 10^seq(10,-2,length=100)
train <- sample(1:nrow(df), nrow(df)/2) 
test <- (-train)
y = df$BMI
y.test <-  y[test]
               
x = model.matrix(BMI ~.,df)[,-1] 
x = x[,-1] # THIS removes HeartDisease predictor
y = df[,1] 


cv.out <- cv.glmnet(x[train,], y[train], alpha=1 ,lambda=grid)
#default performs 10-fold CV, but you can change this using the argument `nfolds` 
plot(cv.out)
bestlambda = cv.out$lambda.min
bestlambda
log(bestlambda) #confirm min aligns with min on plot
lasso.train = glmnet(x[train,],y[train],alpha=1,lambda=grid)

which(grid==bestlambda)
lasso.train$lambda[100]
coef(lasso.train)[,100]

lasso.train.pred = predict(lasso.train,s=bestlambda,newx=x[train,])# on training set only
lasso.pred = predict(lasso.train,s=bestlambda,newx=x[test,]) # evaluating on test set
mean((lasso.pred-y.test)^2) # test MSE

final.lasso = glmnet(x,y,alpha=1,lambda=bestlambda) # fitting on entire data set using optimal lamda
coef(final.lasso)
# 
# plot(performance(ROCRpred,'tnr','fnr'),colorize=TRUE,print.cutoffs.at=seq(0,1,by=0.1), text.adj=c(-0.2,1.7))
# # True negative rate vs false negative rate
lasso_coef=cv.out$glmnet.fit$beta[, cv.out$glmnet.fit$lambda ==bestlambda]
```



# Ridge Regression:
```{r}
set.seed(1)
grid = 10^seq(10,-2,length=100)
train <- sample(1:nrow(df), nrow(df)/2) 
test <- (-train)
y = df$BMI
y.test <-  y[test]
               
x = model.matrix(BMI ~.,df)[,-1] 
y = df[,1] 

ridge.train = glmnet(x[train,],y[train],alpha=0,lambda=grid) # on training set, alpha 0 for ridge regression

cv.out = cv.glmnet(x[train,],y[train],alpha = 0, lambda = grid) 
#default performs 10-fold CV, but you can change this using the argument `nfolds` 
plot(cv.out)
bestlambda = cv.out$lambda.min
bestlambda

## what is the test MSE associated with this value of lambda? 
### glmnet() has its own predict() function! This is different than the predict() 
## we are use to using, so the syntax is slightly different. 

ridge.pred = predict(ridge.train,s=bestlambda,newx=x[test,])
mean((ridge.pred-y.test)^2)

## We can refit the ridge regression model on the full data set, using the value 
## of lambda chosen by cross-validation: 

final = glmnet(x,y,alpha=0,lambda = bestlambda)
coef(final)


ridge_coef2=cv.out$glmnet.fit$beta[, cv.out$glmnet.fit$lambda ==bestlambda]
```

# Ridge Regression: WITHOUT HEART DISEASE Predictor
```{r}
set.seed(1)
grid = 10^seq(10,-2,length=100)
train <- sample(1:nrow(df), nrow(df)/2) 
test <- (-train)
y = df$BMI
y.test <-  y[test]
               
x = model.matrix(BMI ~.,df)[,-1] 
x = x[,-1] # THIS removes HeartDisease predictor
y = df[,1] 

ridge.train = glmnet(x[train,],y[train],alpha=0,lambda=grid) # on training set, alpha 0 for ridge regression

cv.out = cv.glmnet(x[train,],y[train],alpha = 0, lambda = grid) 
#default performs 10-fold CV, but you can change this using the argument `nfolds` 
plot(cv.out)
bestlambda = cv.out$lambda.min
bestlambda

## what is the test MSE associated with this value of lambda? 
### glmnet() has its own predict() function! This is different than the predict() 
## we are use to using, so the syntax is slightly different. 

ridge.pred = predict(ridge.train,s=bestlambda,newx=x[test,])
mean((ridge.pred-y.test)^2)

## We can refit the ridge regression model on the full data set, using the value 
## of lambda chosen by cross-validation: 

final = glmnet(x,y,alpha=0,lambda = bestlambda)
coef(final)


ridge_coef=cv.out$glmnet.fit$beta[, cv.out$glmnet.fit$lambda ==bestlambda]

```
#### This plot is without Heart Disease as predictor. To gain more insight into the other predictors to help predict BMI
```{r}

 # Compare coefficients:
coef = data.table(lasso = lasso_coef, ridge=ridge_coef)
coef[, feature := names(lasso_coef)]
to_plot = melt(coef, id.vars='feature', variable.name='model', value.name='coefficient')

ggplot(to_plot, aes(x=feature, y=coefficient, fill=model)) + coord_flip() +
geom_bar(stat='identity') +
facet_wrap(~ model) + guides (fill=FALSE)



```
#### This plot includes Heart Disease as predictor.
```{r}

 # Compare coefficients:
coef = data.table(lasso = lasso_coef2, ridge=ridge_coef2)
coef[, feature := names(lasso_coef2)]
to_plot = melt(coef, id.vars='feature', variable.name='model', value.name='coefficient')

ggplot(to_plot, aes(x=feature, y=coefficient, fill=model)) + coord_flip() +
geom_bar(stat='identity') +
facet_wrap(~ model) + guides (fill=FALSE)



```
